# ViT Model Editing Pipeline

Transfer LLM editing techniques (AlphaEdit + ASTRA) to Vision Transformers for correcting misclassified samples on MedMNIST (PathMNIST).

## ğŸ¯ Project Goal

1. **Data Splitting**: Rigorously isolate a "Held-Out Validation Set" before any training
2. **Fine-tuning**: Train `vit-base-patch16-224` on PathMNIST
3. **Locate Layers**: Adapt ASTRA to identify significant layers for error samples
4. **Edit Weights**: Adapt AlphaEdit to correct these errors
5. **Evaluate**: Generate Confusion Matrix and Accuracy using the Held-Out set

## ğŸ“ Project Structure

```
d:\ModelEdit\
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_handler.py      # PathMNIST loading & strict train/held-out split
â”‚   â”œâ”€â”€ trainer.py           # ViT fine-tuning with auto GPU/CPU + checkpointing
â”‚   â”œâ”€â”€ locator.py           # ASTRA-based layer importance scoring
â”‚   â”œâ”€â”€ editor.py            # AlphaEdit null-space projection editing
â”‚   â”œâ”€â”€ evaluator.py         # Evaluation with confusion matrix & reports
â”‚   â””â”€â”€ main.py              # CLI entry point
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ vit_pathmnist_finetuned.pt   # Fine-tuned model
â”‚   â””â”€â”€ vit_pathmnist_edited.pt      # Edited model
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ data_split_info.csv          # Dataset split statistics
â”‚   â”œâ”€â”€ training_metrics.csv         # Training loss/accuracy per epoch
â”‚   â”œâ”€â”€ layer_importance.csv         # Per-sample layer importance scores
â”‚   â”œâ”€â”€ layer_statistics.csv         # Aggregated layer statistics
â”‚   â””â”€â”€ edit_log.csv                 # Weight edit records
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ confusion_matrix.csv         # Confusion matrix
â”‚   â”œâ”€â”€ evaluation_report.csv        # Detailed metrics
â”‚   â”œâ”€â”€ predictions.csv              # All predictions with probabilities
â”‚   â””â”€â”€ confusion_matrix.png         # Visualization
â”œâ”€â”€ reference/                        # Reference implementations
â”‚   â”œâ”€â”€ AlphaEdit/                   # Null-space projection method
â”‚   â””â”€â”€ ASTRA/                       # Activation steering method
â”œâ”€â”€ pyproject.toml                   # uv package configuration
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites (ä½¿ç”¨ uv åŒ…ç®¡ç†å™¨)

```bash
# å®‰è£… uv (å¦‚æœå°šæœªå®‰è£…)
# Windows (PowerShell)
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"

# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### ç¯å¢ƒè®¾ç½®

```bash
cd d:\ModelEdit

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ– (uv ä¼šè‡ªåŠ¨è¯»å– pyproject.toml)
uv venv
uv sync

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
```

### Data Location

PathMNIST should be at: `~/.medmnist/pathmnist_224.npz`

### Running the Pipeline

```bash
cd d:\ModelEdit

# ä½¿ç”¨ uv run ç›´æ¥è¿è¡Œ (æ— éœ€æ‰‹åŠ¨æ¿€æ´»ç¯å¢ƒ)
# Stage 1: Prepare data with strict isolation
uv run python src/main.py --stage data

# Stage 2: Fine-tune ViT (auto GPU/CPU detection)
uv run python src/main.py --stage train --epochs 10 --batch-size 32

# Stage 3: Locate important layers (ASTRA)
uv run python src/main.py --stage locate --num-ablations 32

# Stage 4: Apply weight edits (AlphaEdit)
uv run python src/main.py --stage edit --edit-layers 9 10 11 --max-edits 30

# Stage 5: Evaluate on held-out set
uv run python src/main.py --stage eval

# Or run complete pipeline
uv run python src/main.py --stage full --epochs 10
```

### æ‰‹åŠ¨æ¿€æ´»ç¯å¢ƒåè¿è¡Œ

```bash
# æ¿€æ´»ç¯å¢ƒåï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ python
.venv\Scripts\activate  # Windows
python src/main.py --stage full --epochs 10
```

## ğŸ“Š Pipeline Stages

### Stage 1: Data Preparation (`--stage data`)

- Loads PathMNIST (224Ã—224, 9 classes) from local `.npz` file
- Creates **strict train/held-out split** (default 80:20)
- **CRITICAL**: Held-out set is isolated from ALL training and editing
- Exports: `logs/data_split_info.csv`

### Stage 2: Fine-tuning (`--stage train`)

- Uses `google/vit-base-patch16-224` with 9-class head
- **Auto-detects GPU/CPU** for optimal performance
- Saves checkpoints with model weights, optimizer state, and training history
- Exports: `checkpoints/vit_pathmnist_finetuned.pt`, `logs/training_metrics.csv`

### Stage 3: Layer Localization (`--stage locate`)

Adapts **ASTRA methodology** for ViT:
- Patch-level ablation study (zero out 14Ã—14 patches)
- Lasso regression to estimate layer importance
- Analyzes CLS token activations across all 12 encoder layers
- Exports: `logs/layer_importance.csv`, `logs/layer_statistics.csv`

### Stage 4: Weight Editing (`--stage edit`)

Adapts **AlphaEdit** for ViT:
- Collects K vectors (input to `output.dense` layer)
- Computes null-space projection matrix P via SVD
- Optimizes target Z vectors through gradient descent
- Applies update: $\Delta = R K^T P (KK^T P + \lambda I)^{-1}$
- Exports: `logs/edit_log.csv`, `checkpoints/vit_pathmnist_edited.pt`

### Stage 5: Evaluation (`--stage eval`)

- Runs inference on **HELD-OUT set only** (ensures valid evaluation)
- Computes per-class precision, recall, F1
- Generates confusion matrix and visualization
- Exports: `results/confusion_matrix.csv`, `results/evaluation_report.csv`

## ğŸ”§ Key Arguments

| Argument | Default | Description |
|----------|---------|-------------|
| `--stage` | required | Pipeline stage: data, train, locate, edit, eval, full |
| `--data-path` | `~/.medmnist/pathmnist_224.npz` | PathMNIST data file |
| `--held-out-ratio` | 0.2 | Fraction for held-out validation |
| `--epochs` | 10 | Training epochs |
| `--batch-size` | 32 | Batch size |
| `--lr` | 1e-4 | Learning rate |
| `--edit-layers` | 9 10 11 | Layers to edit |
| `--max-edits` | 30 | Maximum samples to edit |
| `--num-ablations` | 32 | Ablations for layer analysis |
| `--seed` | 42 | Random seed |

## ğŸ“ Technical Details

### Data Isolation Rules

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Original Data                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Training Set (80%)    â”‚   Held-Out Set (20%)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ“ Fine-tuning            â”‚ âœ— NEVER used for training   â”‚
â”‚ âœ“ Misclassified analysis â”‚ âœ— NEVER used for editing    â”‚
â”‚ âœ“ Layer localization     â”‚ âœ“ ONLY for final evaluation â”‚
â”‚ âœ“ Weight editing         â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AlphaEdit Formula (Adapted for ViT)

$$\Delta_{\text{AlphaEdit}} = R K^T P (K K^T P + K_p K_p^T P + \lambda I)^{-1}$$

Where:
- $R = V_{\text{target}} - W K$ (residual)
- $P = \hat{U} \hat{U}^T$ (null-space projection)
- $K$ = input activations at CLS token position

### ASTRA Importance Scoring

$$\text{Importance}_l = \sum_{i} |w_i^l|$$

Where $w^l$ are Lasso regression coefficients predicting output probability from layer $l$ activations under random patch ablations.

## ğŸ“ Changelog

### v1.0.1 (2026-01-13)
- è¿ç§»åˆ° **uv** åŒ…ç®¡ç†å™¨
- æ·»åŠ  `pyproject.toml` é…ç½®æ–‡ä»¶
- æ›´æ–°è¿è¡Œå‘½ä»¤ä½¿ç”¨ `uv run`
- åˆ é™¤ `requirements.txt`ï¼Œç»Ÿä¸€ä½¿ç”¨ `pyproject.toml`

### v1.0.0 (2026-01-13)
- Initial implementation
- Created modular pipeline: DataHandler, Trainer, Locator, Editor, Evaluator
- Adapted AlphaEdit null-space projection for ViT MLP layers
- Adapted ASTRA patch-level ablation for layer importance
- Auto GPU/CPU detection for training
- Checkpoint saving with full state (model, optimizer, scheduler, history)
- CLI interface with `--stage` argument
- CSV logging for all stages
- Confusion matrix visualization

## ğŸ”— References

- **AlphaEdit**: Null-space projection for knowledge editing without catastrophic forgetting
- **ASTRA**: Adaptive activation steering for VLM safety
- **ViT**: "An Image is Worth 16x16 Words" (Dosovitskiy et al.)
- **MedMNIST**: Standardized medical image classification benchmark

## âš ï¸ Important Notes

1. **Device Selection**: The pipeline automatically detects and uses GPU if available
2. **Held-Out Isolation**: The held-out set is strictly isolated - never used during training or editing
3. **Checkpoint Format**: Checkpoints include model weights, optimizer state, scheduler state, and full training history
4. **Reproducibility**: Use `--seed` argument for reproducible results
