# ViT Model Editing Pipeline

Transfer LLM editing techniques (AlphaEdit) to Vision Transformers for correcting misclassified samples on MedMNIST (PathMNIST).

## ğŸ¯ Project Goal

1. **Data Splitting**: Rigorously isolate a "Held-Out Validation Set" before any training
2. **Fine-tuning**: Train `vit-base-patch16-224` on PathMNIST
3. **Locate Layers**: Use AlphaEdit-style **Causal Tracing** to identify significant layers for error samples
4. **Edit Weights**: Adapt AlphaEdit to correct these errors
5. **Evaluate**: Generate Confusion Matrix and Accuracy using the Held-Out set

## ğŸ“ Project Structure

```
d:\ModelEdit\
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_handler.py      # PathMNIST loading & strict train/held-out split
â”‚   â”œâ”€â”€ trainer.py           # ViT fine-tuning with auto GPU/CPU + checkpointing
â”‚   â”œâ”€â”€ locator.py           # AlphaEdit-style causal tracing for layer importance
â”‚   â”œâ”€â”€ editor.py            # AlphaEdit null-space projection editing
â”‚   â”œâ”€â”€ evaluator.py         # Evaluation with confusion matrix & reports
â”‚   â””â”€â”€ main.py              # CLI entry point
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ vit_pathmnist_finetuned.pt   # Fine-tuned model
â”‚   â””â”€â”€ vit_pathmnist_edited.pt      # Edited model
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ data_split_info.csv          # Dataset split statistics
â”‚   â”œâ”€â”€ training_metrics.csv         # Training loss/accuracy per epoch
â”‚   â”œâ”€â”€ causal_trace_results.csv     # Per-sample causal tracing scores
â”‚   â”œâ”€â”€ layer_statistics.csv         # Aggregated layer statistics
â”‚   â””â”€â”€ edit_log.csv                 # Weight edit records
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ confusion_matrix.csv         # Confusion matrix
â”‚   â”œâ”€â”€ evaluation_report.csv        # Detailed metrics
â”‚   â”œâ”€â”€ predictions.csv              # All predictions with probabilities
â”‚   â””â”€â”€ confusion_matrix.png         # Visualization
â”œâ”€â”€ reference/                        # Reference implementations
â”‚   â”œâ”€â”€ AlphaEdit/                   # Null-space projection method
â”‚   â””â”€â”€ ASTRA/                       # Activation steering method
â”œâ”€â”€ pyproject.toml                   # uv package configuration
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites (ä½¿ç”¨ uv åŒ…ç®¡ç†å™¨)

```bash
# å®‰è£… uv (å¦‚æœå°šæœªå®‰è£…)
# Windows (PowerShell)
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"

# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### ç¯å¢ƒè®¾ç½®

```bash
cd d:\ModelEdit

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ– (uv ä¼šè‡ªåŠ¨è¯»å– pyproject.toml)
uv venv
uv sync

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
```

### Data Location

PathMNIST should be at: `~/.medmnist/pathmnist_224.npz`

### Running the Pipeline

```bash
cd d:\ModelEdit

# ä½¿ç”¨ uv run ç›´æ¥è¿è¡Œ (æ— éœ€æ‰‹åŠ¨æ¿€æ´»ç¯å¢ƒ)
# Stage 1: Prepare data with strict isolation
uv run python src/main.py --stage data

# Stage 2: Fine-tune ViT (auto GPU/CPU detection)
uv run python src/main.py --stage train --epochs 10 --batch-size 32

# Stage 3: Locate important layers (Causal Tracing)
uv run python src/main.py --stage locate --noise-factor 3.0

# Stage 4: Apply weight edits (AlphaEdit)
uv run python src/main.py --stage edit --edit-layers 9 10 11 --max-edits 30

# Stage 5: Evaluate on held-out set
uv run python src/main.py --stage eval

# Or run complete pipeline
uv run python src/main.py --stage full --epochs 10
```

### æ‰‹åŠ¨æ¿€æ´»ç¯å¢ƒåè¿è¡Œ

```bash
# æ¿€æ´»ç¯å¢ƒåï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ python
.venv\Scripts\activate  # Windows
python src/main.py --stage full --epochs 10
```

## ğŸ“Š Pipeline Stages

### Stage 1: Data Preparation (`--stage data`)

- Loads PathMNIST (224Ã—224, 9 classes) from local `.npz` file
- Creates **strict train/held-out split** (default 80:20)
- **CRITICAL**: Held-out set is isolated from ALL training and editing
- Exports: `logs/data_split_info.csv`

### Stage 2: Fine-tuning (`--stage train`)

- Uses `google/vit-base-patch16-224` with 9-class head
- **Auto-detects GPU/CPU** for optimal performance
- Saves checkpoints with model weights, optimizer state, and training history
- Exports: `checkpoints/vit_pathmnist_finetuned.pt`, `logs/training_metrics.csv`

### Stage 3: Layer Localization (`--stage locate`)

Adapts **AlphaEdit Causal Tracing** methodology for ViT:

**Core Algorithm:**
1. **Corrupt Input**: Add Gaussian noise to patch embeddings (positions 1-196)
2. **Run Corrupted Forward**: Observe prediction probability drop
3. **Restore & Measure**: For each (token, layer) pair, restore clean activations and measure probability recovery
4. **Importance Score**: Higher recovery = more important layer

**Key Functions (corresponding to AlphaEdit):**
| locator.py | AlphaEdit/causal_trace.py |
|------------|---------------------------|
| `trace_with_patch()` | `trace_with_patch()` |
| `trace_important_states()` | `trace_important_states()` |
| `trace_important_window()` | `trace_important_window()` |
| `collect_embedding_std()` | `collect_embedding_std()` |

**ViT Adaptations:**
- Token 0 = CLS token (classification), Tokens 1-196 = image patches
- Default: corrupt all patches, analyze CLS token restoration
- Noise level auto-calibrated from embedding std (factor Ã— std)

Exports: `logs/causal_trace_results.csv`, `logs/layer_statistics.csv`

### Stage 4: Weight Editing (`--stage edit`)

Adapts **AlphaEdit** for ViT:
- Collects K vectors (input to `output.dense` layer)
- Computes null-space projection matrix P via SVD
- Optimizes target Z vectors through gradient descent
- Applies update: $\Delta = R K^T P (KK^T P + \lambda I)^{-1}$
- Exports: `logs/edit_log.csv`, `checkpoints/vit_pathmnist_edited.pt`

### Stage 5: Evaluation (`--stage eval`)

- Runs inference on **HELD-OUT set only** (ensures valid evaluation)
- Computes per-class precision, recall, F1
- Generates confusion matrix and visualization
- Exports: `results/confusion_matrix.csv`, `results/evaluation_report.csv`

## ğŸ”§ Key Arguments

| Argument | Default | Description |
|----------|---------|-------------|
| `--stage` | required | Pipeline stage: data, train, locate, edit, eval, full |
| `--data-path` | `~/.medmnist/pathmnist_224.npz` | PathMNIST data file |
| `--held-out-ratio` | 0.2 | Fraction for held-out validation |
| `--epochs` | 10 | Training epochs |
| `--batch-size` | 32 | Batch size |
| `--lr` | 1e-4 | Learning rate |
| `--edit-layers` | 9 10 11 | Layers to edit |
| `--max-edits` | 30 | Maximum samples to edit |
| `--noise-factor` | 3.0 | Noise multiplier for causal tracing |
| `--trace-samples` | 10 | Number of corrupted samples for averaging |
| `--seed` | 42 | Random seed |

## ğŸ“ Technical Details

### Data Isolation Rules

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Original Data                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Training Set (80%)    â”‚   Held-Out Set (20%)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ“ Fine-tuning            â”‚ âœ— NEVER used for training   â”‚
â”‚ âœ“ Misclassified analysis â”‚ âœ— NEVER used for editing    â”‚
â”‚ âœ“ Layer localization     â”‚ âœ“ ONLY for final evaluation â”‚
â”‚ âœ“ Weight editing         â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AlphaEdit Formula (Adapted for ViT)

$$\Delta_{\text{AlphaEdit}} = R K^T P (K K^T P + K_p K_p^T P + \lambda I)^{-1}$$

Where:
- $R = V_{\text{target}} - W K$ (residual)
- $P = \hat{U} \hat{U}^T$ (null-space projection)
- $K$ = input activations at CLS token position

### Causal Tracing (Adapted from AlphaEdit)

The causal tracing algorithm identifies which layers are most important for a prediction:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Causal Tracing Process                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Clean Run:     image â†’ [embed] â†’ [L0] â†’ ... â†’ [L11] â†’ P_high â”‚
â”‚                                                                  â”‚
â”‚ 2. Corrupted Run: image â†’ [embed + noise] â†’ ... â†’ P_low         â”‚
â”‚                           â†‘                                      â”‚
â”‚                    (add Gaussian noise to patch embeddings)      â”‚
â”‚                                                                  â”‚
â”‚ 3. Restore Layer: image â†’ [embed + noise] â†’ [L_i restored] â†’ P_iâ”‚
â”‚                                              â†‘                   â”‚
â”‚                         (copy clean activation from run 1)       â”‚
â”‚                                                                  â”‚
â”‚ 4. Importance:    score_i = (P_i - P_low) / (P_high - P_low)    â”‚
â”‚                   (higher = more important for prediction)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Mathematical Formulation:**

For each layer $l$ and token position $t$:
$$\text{Importance}(t, l) = \frac{P(\text{restore } h_l^t) - P(\text{corrupted})}{P(\text{clean}) - P(\text{corrupted})}$$

Where:
- $h_l^t$ = hidden state at layer $l$, token position $t$
- $P(\cdot)$ = probability of target class

## ğŸ“ Changelog

### v1.1.0 (2026-01-14)
- **é‡æ„ Locator æ¨¡å—**: ä» ASTRA é£æ ¼çš„ patch ablation + Lasso å›å½’æ”¹ä¸º AlphaEdit é£æ ¼çš„ **å› æœè¿½è¸ª (Causal Tracing)**
- æ–°å¢ `trace_with_patch()`: å¯¹ patch embeddings æ·»åŠ å™ªå£°å¹¶æ¢å¤ç‰¹å®šå±‚æ¿€æ´»
- æ–°å¢ `trace_important_states()`: éå†æ‰€æœ‰ (token, layer) ç»„åˆæµ‹é‡é‡è¦æ€§
- æ–°å¢ `trace_important_window()`: ä½¿ç”¨æ»‘åŠ¨çª—å£åˆ†æ attention/MLP ç»„ä»¶
- æ–°å¢ `collect_embedding_std()`: è‡ªåŠ¨ä¼°è®¡å™ªå£°æ°´å¹³
- æ–°å¢ `CausalTracer` ç±»: å°è£…å› æœè¿½è¸ªåˆ†æ
- æ›´æ–° `Locator` ç±»æ¥å£ä»¥ä½¿ç”¨å› æœè¿½è¸ª
- ä¸ AlphaEdit `experiments/causal_trace.py` æ–¹æ³•è®ºå¯¹é½

### v1.0.1 (2026-01-13)
- è¿ç§»åˆ° **uv** åŒ…ç®¡ç†å™¨
- æ·»åŠ  `pyproject.toml` é…ç½®æ–‡ä»¶
- æ›´æ–°è¿è¡Œå‘½ä»¤ä½¿ç”¨ `uv run`
- åˆ é™¤ `requirements.txt`ï¼Œç»Ÿä¸€ä½¿ç”¨ `pyproject.toml`

### v1.0.0 (2026-01-13)
- Initial implementation
- Created modular pipeline: DataHandler, Trainer, Locator, Editor, Evaluator
- Adapted AlphaEdit null-space projection for ViT MLP layers
- Adapted ASTRA patch-level ablation for layer importance
- Auto GPU/CPU detection for training
- Checkpoint saving with full state (model, optimizer, scheduler, history)
- CLI interface with `--stage` argument
- CSV logging for all stages
- Confusion matrix visualization

## ğŸ”— References

- **AlphaEdit**: Null-space projection for knowledge editing without catastrophic forgetting
  - Causal tracing: `experiments/causal_trace.py`
  - Weight editing: `AlphaEdit/AlphaEdit_main.py`
- **ViT**: "An Image is Worth 16x16 Words" (Dosovitskiy et al.)
- **MedMNIST**: Standardized medical image classification benchmark

## âš ï¸ Important Notes

1. **Device Selection**: The pipeline automatically detects and uses GPU if available
2. **Held-Out Isolation**: The held-out set is strictly isolated - never used during training or editing
3. **Checkpoint Format**: Checkpoints include model weights, optimizer state, scheduler state, and full training history
4. **Reproducibility**: Use `--seed` argument for reproducible results
